{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "pLOm4rYAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Yuanxin Liu", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=pLOm4rYAAAAJ&citpid=4", "affiliation": "Peking University", "organization": 10725744176602846184, "interests": ["Natural Language Processing"], "email_domain": "@stu.pku.edu.cn", "homepage": "https://llyx97.github.io/", "citedby": 669, "publications": {"pLOm4rYAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Aligning visual regions and textual concepts for semantic-grounded image representations", "pub_year": "2019"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:d1gkVwhDpl0C", "num_citations": 135, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2159125820163720413", "cites_id": ["2159125820163720413"]}, "pLOm4rYAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "simnet: Stepwise image-topic merging network for generating detailed and comprehensive image captions", "pub_year": "2018"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:9yKSN-GCB0IC", "num_citations": 120, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5709649317619862029", "cites_id": ["5709649317619862029"]}, "pLOm4rYAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Exploring and distilling cross-modal information for image captioning", "pub_year": "2020"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:u5HHmVD_uO8C", "num_citations": 77, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13329023829002422855", "cites_id": ["13329023829002422855"]}, "pLOm4rYAAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Tempcompass: Do video llms really understand videos?", "pub_year": "2024"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:hqOjcs7Dif8C", "num_citations": 57, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11817956159221163179", "cites_id": ["11817956159221163179"]}, "pLOm4rYAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Fetv: A benchmark for fine-grained evaluation of open-domain text-to-video generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:UebtZRa9Y70C", "num_citations": 55, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16797871499191104183", "cites_id": ["16797871499191104183"]}, "pLOm4rYAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards robust visual question answering: Making the most of biased samples via contrastive learning", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:_FxGoFyzp5QC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15087191019749082650", "cites_id": ["15087191019749082650"]}, "pLOm4rYAAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deco: Decoupling token compression from semantic abstraction in multimodal large language models", "pub_year": "2024"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:5nxA0vEk-isC", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16315909502816627502", "cites_id": ["16315909502816627502"]}, "pLOm4rYAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Language prior is not the only shortcut: A benchmark for shortcut learning in vqa", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:LkGwnXOMwfcC", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2105777161210243794", "cites_id": ["2105777161210243794"]}, "pLOm4rYAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Generating paraphrase with topic as prior knowledge", "pub_year": "2019"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:u-x6o8ySG0sC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1925416115148640484", "cites_id": ["1925416115148640484"]}, "pLOm4rYAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-adaptive scaling for learnable residual structure", "pub_year": "2019"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:W7OEmFMy1HYC", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17790918364311479917", "cites_id": ["17790918364311479917"]}, "pLOm4rYAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rosita: Refined bert compression with integrated techniques", "pub_year": "2021"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:zYLM7Y9cAGgC", "num_citations": 19, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=141946000252938968", "cites_id": ["141946000252938968"]}, "pLOm4rYAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Vitatecs: A diagnostic dataset for temporal concept understanding of video-language models", "pub_year": "2024"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:0EnyYjriUFMC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1988283831992714017", "cites_id": ["1988283831992714017"]}, "pLOm4rYAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Connecting targets via latent topics and contrastive learning: A unified framework for robust zero-shot and few-shot stance detection", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:WF5omc3nYNoC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1174931634700723396", "cites_id": ["1174931634700723396"]}, "pLOm4rYAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning to win lottery tickets in BERT transfer via task-agnostic mask training", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:eQOLeE2rZwMC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10681388987449318576", "cites_id": ["10681388987449318576"]}, "pLOm4rYAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ranking and sampling in open-domain question answering", "pub_year": "2019"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:UeHWp8X0CEIC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5473614580487966446", "cites_id": ["5473614580487966446"]}, "pLOm4rYAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning class-transductive intent representations for zero-shot intent detection", "pub_year": "2020"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:YsMSGLbcyi4C", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9100737528742736579", "cites_id": ["9100737528742736579"]}, "pLOm4rYAAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unsupervised pre-training for natural language generation: A literature review", "pub_year": "2019"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:IjCSPb-OGe4C", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2512364126262955483", "cites_id": ["2512364126262955483"]}, "pLOm4rYAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A win-win deal: Towards sparse and robust pre-trained language models", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:ufrVoPGSRksC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12965321937141963299", "cites_id": ["12965321937141963299"]}, "pLOm4rYAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Marginal Utility Diminishes: Exploring the Minimum Knowledge for BERT Knowledge Distillation", "pub_year": "2021"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:Tyk-4Ss8FVUC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1922667977439296686", "cites_id": ["1922667977439296686"]}, "pLOm4rYAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Aligning visual regions and textual concepts: Learning fine-grained image representations for image captioning", "pub_year": "2019"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:qjMakFHDy7sC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9173674357976862635", "cites_id": ["9173674357976862635"]}, "pLOm4rYAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Cost-eff: Collaborative optimization of spatial and temporal efficiency with slenderized multi-exit language models", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:roLk4NBRz8UC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14246026446941228580", "cites_id": ["14246026446941228580"]}, "pLOm4rYAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Temporal reasoning transfer from text to video", "pub_year": "2024"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:MXK_kJrjxJIC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2970488385762800496", "cites_id": ["2970488385762800496"]}, "pLOm4rYAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Multimodal Video Paragraph Captioning Models Robust to Missing Modality", "pub_year": "2024"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:8k81kl-MbHgC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17659477999738976586", "cites_id": ["17659477999738976586"]}, "pLOm4rYAAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Compressing and Debiasing Vision-Language Pre-Trained Models for Visual Question Answering", "pub_year": "2022"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:Se3iqnhoufwC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7546977239770852905", "cites_id": ["7546977239770852905"]}, "pLOm4rYAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning Disentangled Intent Representations for Zero-shot Intent Detection.", "pub_year": "2012"}, "filled": false, "author_pub_id": "pLOm4rYAAAAJ:Y0pCki6q_DkC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3744170661735523851", "cites_id": ["3744170661735523851"]}}, "citedby5y": 639, "hindex": 13, "hindex5y": 13, "i10index": 14, "i10index5y": 14, "cites_per_year": {"2018": 8, "2019": 19, "2020": 52, "2021": 114, "2022": 113, "2023": 90, "2024": 220, "2025": 49}, "updated": "2025-02-28 08:10:19.040057"}